{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkgfS0HujSHdiWjvFDXC01",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alwaysneedhelp/AI-Challenge/blob/main/advertisement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Importing Necessary Libraries***"
      ],
      "metadata": {
        "id": "klFm9qcB8aRR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNrxF_YSsLR0",
        "outputId": "35f28d70-5a25-4b85-910d-987e20014513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import matplotlib as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from google.colab import drive\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "import random\n",
        "import zipfile\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Loading Training Data***"
      ],
      "metadata": {
        "id": "rcYLo5vb7vHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the train.csv from mydrive to local colab, so it is easier to work with it\n",
        "\n",
        "if not (os.path.isfile('train.csv')):\n",
        "  !cp '/content/drive/MyDrive/AI_Challenge_advertisement_train.csv' train.csv\n",
        "\n",
        "df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "QH6e8cSPsbou"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the results reproducible using seed\n",
        "\n",
        "SEED = 42\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)"
      ],
      "metadata": {
        "id": "f7X3VAevuL5G"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all the images from drive to my folder\n",
        "\n",
        "if not (os.path.exists('./images')):\n",
        "  !cp '/content/drive/MyDrive/images.zip' . # Using cp extract the file from google drive to a local folder\n",
        "  with zipfile.ZipFile('images.zip', 'r') as f:\n",
        "    f.extractall('./images')"
      ],
      "metadata": {
        "id": "os3ckJSC3RcB"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Img_Dataset(Dataset):\n",
        "  def __init__(self, df, transform=None, img_dir='./images'):\n",
        "    self.file_names = df['image'].tolist()\n",
        "    self.labels = df['class'].tolist()\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.file_names)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, self.file_names[idx])\n",
        "    image = Image.open(img_path).convert('RGB')\n",
        "    label = self.labels[idx]\n",
        "\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return image, label, self.file_names[idx]"
      ],
      "metadata": {
        "id": "ZMyJSnKk_qKL"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking some part of the data for validation, as we don't necessarily need it\n",
        "# (Since there is a lot of training data)\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state = SEED\n",
        ")"
      ],
      "metadata": {
        "id": "wn21_01pGdDS"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485,0.456,0.406],\n",
        "                [0.229,0.224,0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "A7mJ1LXYrdzL"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Img_Dataset(\n",
        "    train_df,\n",
        "    transform = transformer)\n",
        "val_dataset = Img_Dataset(\n",
        "    val_df,\n",
        "    transform = transformer)"
      ],
      "metadata": {
        "id": "D4HMjWD-J717"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a loder to load all the data\n",
        "\n",
        "# Trying different batches starting off with 8, since we have a lot of data, but still the dataset isn't that large\n",
        "\n",
        "BATCH = 8\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = BATCH,\n",
        "    shuffle = True, # Shuffling data when loading it\n",
        "    num_workers = 2, # Put 2 workers, so that process goes faster\n",
        "    drop_last = True # Drop everything that remains after placing data into batches of 8\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size = BATCH,\n",
        "    shuffle = True,\n",
        "    num_workers = 2,\n",
        "    drop_last = True\n",
        ")"
      ],
      "metadata": {
        "id": "zfla8BRVTJ7m"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Use Pretrained ResNet50 Model as BackBone***"
      ],
      "metadata": {
        "id": "cXyPKwBCoKwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_model():\n",
        "\n",
        "    # Load a pretrained ResNet50 backbone\n",
        "    m = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "\n",
        "    # Getting how many features were input for the lasat layer\n",
        "    in_features = m.fc.in_features\n",
        "\n",
        "    # Replace the 1000-class head with a single-logit head\n",
        "    m.fc = nn.Linear(in_features, 1)\n",
        "    return m\n",
        "\n",
        "\n",
        "model = prepare_model()"
      ],
      "metadata": {
        "id": "kuj31JqWoGmu"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Preparing Everything Needed for Training***"
      ],
      "metadata": {
        "id": "ydoqdIAX37PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# I need a balanced loss function, since the dataset is balanced (ig) (haven't taken a look at it yet tbh)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Use the common, simple Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Use scheduler to regulate lr\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
        "\n",
        "# Use scaler to reduce the memory usage\n",
        "scaler = torch.amp.GradScaler(DEVICE)"
      ],
      "metadata": {
        "id": "zJB7NMcyrNzY"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, scaler, epochs):\n",
        "  model.train()\n",
        "  model.to(DEVICE)\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch}')\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0.0\n",
        "\n",
        "    for imgs, labels, _ in loader:\n",
        "      imgs = imgs.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Reshape labels to match output shape and cast to float\n",
        "      labels = labels.view(-1, 1).float()\n",
        "\n",
        "      with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Only scale if using GPU\n",
        "        if DEVICE == \"cuda\":\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # For binary classification with BCEWithLogitsLoss, use sigmoid and threshold for predictions\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        correct += (labels == preds).sum().item()\n",
        "\n",
        "\n",
        "    running_loss /= len(loader)\n",
        "    accuracy = 100. * correct / len(loader.dataset)\n",
        "\n",
        "    print(f'Training Loss: {running_loss:.4f}')\n",
        "    print(f'Training Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "\n",
        "  return model, running_loss, accuracy"
      ],
      "metadata": {
        "id": "W1cF2JGAvgjx"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Training***"
      ],
      "metadata": {
        "id": "NSbOWU9u4W0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, train_loss, train_acc = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    optimizer,\n",
        "    scaler,\n",
        "    10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNLN1m_J3Uqd",
        "outputId": "b202529f-1c68-40e9-cda8-239af59e0751"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-134103086.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1083\n",
            "Training Accuracy: 92.96%\n",
            "Epoch 1\n",
            "Training Loss: 0.0475\n",
            "Training Accuracy: 97.04%\n",
            "Epoch 2\n",
            "Training Loss: 0.1304\n",
            "Training Accuracy: 94.81%\n",
            "Epoch 3\n",
            "Training Loss: 0.0346\n",
            "Training Accuracy: 97.04%\n",
            "Epoch 4\n",
            "Training Loss: 0.0489\n",
            "Training Accuracy: 97.04%\n",
            "Epoch 5\n",
            "Training Loss: 0.0784\n",
            "Training Accuracy: 94.44%\n",
            "Epoch 6\n",
            "Training Loss: 0.0165\n",
            "Training Accuracy: 97.78%\n",
            "Epoch 7\n",
            "Training Loss: 0.0053\n",
            "Training Accuracy: 97.78%\n",
            "Epoch 8\n",
            "Training Loss: 0.0016\n",
            "Training Accuracy: 97.78%\n",
            "Epoch 9\n",
            "Training Loss: 0.0005\n",
            "Training Accuracy: 97.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solid results on training"
      ],
      "metadata": {
        "id": "r6UJyBnbJYIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Validation***"
      ],
      "metadata": {
        "id": "JsZV1eDkJaki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def val_report(model, loader, threshold):\n",
        "    model.eval()\n",
        "    all_probs, all_lbls = [], []\n",
        "    for imgs, labels, _ in loader:\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        outputs = model(imgs)\n",
        "        probs = torch.sigmoid(outputs).squeeze(1).detach().cpu().numpy()\n",
        "        all_probs.append(probs)\n",
        "        all_lbls.extend(labels.numpy())\n",
        "    all_probs = np.concatenate(all_probs)\n",
        "    preds = (all_probs >= threshold).astype(int)\n",
        "    print(\"F1:\", f1_score(all_lbls, preds))\n",
        "\n",
        "\n",
        "val_report(\n",
        "    model,\n",
        "    val_loader,\n",
        "    0.5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOPCJowkJfBL",
        "outputId": "43149d3c-dce7-4581-83c8-9ca95894ed15"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Damn, this is high"
      ],
      "metadata": {
        "id": "Afse7sRSK1w3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Save This Model***"
      ],
      "metadata": {
        "id": "fMaZTeUSK-TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not (os.path.isfile('model.pth')):\n",
        "  torch.save(model.state_dict(), 'model.pth')"
      ],
      "metadata": {
        "id": "wnHYqTAELCTH"
      },
      "execution_count": 132,
      "outputs": []
    }
  ]
}