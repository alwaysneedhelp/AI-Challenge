{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "klFm9qcB8aRR",
        "RfzSpMGxMpJk",
        "I1_1lvc3MZrS",
        "h4icUqqgMi44",
        "EzjLOyU6M57W",
        "WJDybT9ANBOm",
        "skODRpAiNLjW",
        "cXyPKwBCoKwG",
        "ydoqdIAX37PA",
        "NSbOWU9u4W0q",
        "JsZV1eDkJaki",
        "fMaZTeUSK-TP"
      ],
      "authorship_tag": "ABX9TyN6+KnmI2HuQXO4oBENuiwu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alwaysneedhelp/AI-Challenge/blob/main/advertisement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Importing Necessary Libraries***"
      ],
      "metadata": {
        "id": "klFm9qcB8aRR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNrxF_YSsLR0",
        "outputId": "35f28d70-5a25-4b85-910d-987e20014513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import matplotlib as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from google.colab import drive\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "import random\n",
        "import zipfile\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Loading Training Data***"
      ],
      "metadata": {
        "id": "rcYLo5vb7vHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Extracting needed files from google drive***"
      ],
      "metadata": {
        "id": "RfzSpMGxMpJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the train.csv from mydrive to local colab, so it is easier to work with it\n",
        "\n",
        "if not (os.path.isfile('train.csv')):\n",
        "  !cp '/content/drive/MyDrive/AI_Challenge_advertisement_train.csv' train.csv\n",
        "\n",
        "df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "QH6e8cSPsbou"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all the images from drive to my folder\n",
        "\n",
        "if not (os.path.exists('./images')):\n",
        "  !cp '/content/drive/MyDrive/images.zip' . # Using cp extract the file from google drive to a local folder\n",
        "  with zipfile.ZipFile('images.zip', 'r') as f:\n",
        "    f.extractall('./images')"
      ],
      "metadata": {
        "id": "os3ckJSC3RcB"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Making sure the Results are Reproducible***"
      ],
      "metadata": {
        "id": "I1_1lvc3MZrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the results reproducible using seed\n",
        "\n",
        "SEED = 42\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)"
      ],
      "metadata": {
        "id": "f7X3VAevuL5G"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Splitting Data and Preparing the Preprocess Transformer***"
      ],
      "metadata": {
        "id": "h4icUqqgMi44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking some part of the data for validation, as we don't necessarily need it\n",
        "# (Since there is a lot of training data)\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state = SEED\n",
        ")"
      ],
      "metadata": {
        "id": "wn21_01pGdDS"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485,0.456,0.406],\n",
        "                [0.229,0.224,0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "A7mJ1LXYrdzL"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Creating Dataset***"
      ],
      "metadata": {
        "id": "EzjLOyU6M57W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Img_Dataset(Dataset):\n",
        "  def __init__(self, df, transform=None, img_dir='./images', labels=True):\n",
        "    self.file_names = df['image'].tolist()\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.labels = False\n",
        "\n",
        "    # Just to not create a separate class for test\n",
        "    # Adding extra-check if labels exist in the given df\n",
        "\n",
        "    if labels:\n",
        "      self.labels = df['class'].tolist()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.file_names)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, self.file_names[idx])\n",
        "    image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    if self.labels:\n",
        "      label = self.labels[idx]\n",
        "      return image, label, self.file_names[idx]\n",
        "\n",
        "    return image, self.file_names[idx]"
      ],
      "metadata": {
        "id": "ZMyJSnKk_qKL"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Img_Dataset(\n",
        "    train_df,\n",
        "    transform = transformer)\n",
        "val_dataset = Img_Dataset(\n",
        "    val_df,\n",
        "    transform = transformer)"
      ],
      "metadata": {
        "id": "D4HMjWD-J717"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Load Data from Dataset***"
      ],
      "metadata": {
        "id": "WJDybT9ANBOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a loder to load all the data\n",
        "\n",
        "# Trying different batches starting off with 8, since we have a lot of data, but still the dataset isn't that large\n",
        "\n",
        "BATCH = 8\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = BATCH,\n",
        "    shuffle = True, # Shuffling data when loading it\n",
        "    num_workers = 2, # Put 2 workers, so that process goes faster\n",
        "    drop_last = True # Drop everything that remains after placing data into batches of 8\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size = BATCH,\n",
        "    shuffle = True,\n",
        "    num_workers = 2,\n",
        "    drop_last = True\n",
        ")"
      ],
      "metadata": {
        "id": "zfla8BRVTJ7m"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Train the Model***"
      ],
      "metadata": {
        "id": "skODRpAiNLjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Use Pretrained ResNet50 Model as BackBone***"
      ],
      "metadata": {
        "id": "cXyPKwBCoKwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_model():\n",
        "\n",
        "    # Load a pretrained ResNet50 backbone\n",
        "    m = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "\n",
        "    # Getting how many features were input for the lasat layer\n",
        "    in_features = m.fc.in_features\n",
        "\n",
        "    # Replace the 1000-class head with a single-logit head\n",
        "    m.fc = nn.Linear(in_features, 1)\n",
        "    return m\n",
        "\n",
        "\n",
        "model = prepare_model()"
      ],
      "metadata": {
        "id": "kuj31JqWoGmu"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Preparing Everything Needed for Training***"
      ],
      "metadata": {
        "id": "ydoqdIAX37PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# I need a balanced loss function, since the dataset is balanced (ig) (haven't taken a look at it yet tbh)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Use the common, simple Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Use scheduler to regulate lr\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
        "\n",
        "# Use scaler to reduce the memory usage\n",
        "scaler = torch.amp.GradScaler(DEVICE)"
      ],
      "metadata": {
        "id": "zJB7NMcyrNzY"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, scaler, epochs):\n",
        "  model.train()\n",
        "  model.to(DEVICE)\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch}')\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0.0\n",
        "\n",
        "    for imgs, labels, _ in loader:\n",
        "      imgs = imgs.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Reshape labels to match output shape and cast to float\n",
        "      labels = labels.view(-1, 1).float()\n",
        "\n",
        "      with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Only scale if using GPU\n",
        "        if DEVICE == \"cuda\":\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # For binary classification with BCEWithLogitsLoss, use sigmoid and threshold for predictions\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        correct += (labels == preds).sum().item()\n",
        "\n",
        "\n",
        "    running_loss /= len(loader)\n",
        "    accuracy = 100. * correct / len(loader.dataset)\n",
        "\n",
        "    print(f'Training Loss: {running_loss:.4f}')\n",
        "    print(f'Training Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "\n",
        "  return model, running_loss, accuracy"
      ],
      "metadata": {
        "id": "W1cF2JGAvgjx"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Training***"
      ],
      "metadata": {
        "id": "NSbOWU9u4W0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, train_loss, train_acc = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    optimizer,\n",
        "    scaler,\n",
        "    10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNLN1m_J3Uqd",
        "outputId": "b202529f-1c68-40e9-cda8-239af59e0751"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-134103086.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1083\n",
            "Training Accuracy: 92.96%\n",
            "Epoch 1\n",
            "Training Loss: 0.0475\n",
            "Training Accuracy: 97.04%\n",
            "Epoch 2\n",
            "Training Loss: 0.1304\n",
            "Training Accuracy: 94.81%\n",
            "Epoch 3\n",
            "Training Loss: 0.0346\n",
            "Training Accuracy: 97.04%\n",
            "Epoch 4\n",
            "Training Loss: 0.0489\n",
            "Training Accuracy: 97.04%\n",
            "Epoch 5\n",
            "Training Loss: 0.0784\n",
            "Training Accuracy: 94.44%\n",
            "Epoch 6\n",
            "Training Loss: 0.0165\n",
            "Training Accuracy: 97.78%\n",
            "Epoch 7\n",
            "Training Loss: 0.0053\n",
            "Training Accuracy: 97.78%\n",
            "Epoch 8\n",
            "Training Loss: 0.0016\n",
            "Training Accuracy: 97.78%\n",
            "Epoch 9\n",
            "Training Loss: 0.0005\n",
            "Training Accuracy: 97.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solid results on training"
      ],
      "metadata": {
        "id": "r6UJyBnbJYIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Validation***"
      ],
      "metadata": {
        "id": "JsZV1eDkJaki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def val_report(model, loader, threshold):\n",
        "    model.eval()\n",
        "    all_probs, all_lbls = [], []\n",
        "    for imgs, labels, _ in loader:\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        outputs = model(imgs)\n",
        "        probs = torch.sigmoid(outputs).squeeze(1).detach().cpu().numpy()\n",
        "        all_probs.append(probs)\n",
        "        all_lbls.extend(labels.numpy())\n",
        "    all_probs = np.concatenate(all_probs)\n",
        "    preds = (all_probs >= threshold).astype(int)\n",
        "    print(\"F1:\", f1_score(all_lbls, preds))\n",
        "\n",
        "\n",
        "val_report(\n",
        "    model,\n",
        "    val_loader,\n",
        "    0.5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOPCJowkJfBL",
        "outputId": "43149d3c-dce7-4581-83c8-9ca95894ed15"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Damn, this is high"
      ],
      "metadata": {
        "id": "Afse7sRSK1w3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Save This Model***"
      ],
      "metadata": {
        "id": "fMaZTeUSK-TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not (os.path.isfile('model.pth')):\n",
        "  torch.save(model.state_dict(), 'model.pth')"
      ],
      "metadata": {
        "id": "wnHYqTAELCTH"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Now, Predict the Results for Test Data***"
      ],
      "metadata": {
        "id": "4T0oLWKeL1y5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Extract Files from GoogleDrive first***"
      ],
      "metadata": {
        "id": "HAMgQpFWMIor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the test.csv from mydrive to local colab, so it is easier to work with it\n",
        "\n",
        "if not (os.path.isfile('test.csv')):\n",
        "  !cp '/content/drive/MyDrive/AI_Challenge_advertisement_test.csv' test.csv\n",
        "\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "R8JHVad-L5tJ"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Load the Data***"
      ],
      "metadata": {
        "id": "6ZOztIk7R-cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = Img_Dataset(\n",
        "    test_df,\n",
        "    transformer,\n",
        "    labels = False\n",
        ")"
      ],
      "metadata": {
        "id": "Yx7-m3rrPN0J"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = BATCH,\n",
        "    num_workers = 2,\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "SqmE0hSGRYbZ"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Predict***"
      ],
      "metadata": {
        "id": "wibKySHISDrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and store all the predictions\n",
        "\n",
        "all_probs, all_names = [], []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for imgs, names in test_loader:\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        outputs = model(imgs)\n",
        "        probs = torch.sigmoid(outputs).squeeze(1).cpu().numpy()\n",
        "        all_probs.append(probs)\n",
        "        all_names.extend(names)"
      ],
      "metadata": {
        "id": "4aAtGMwySKFq"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gathering all of them, and writing them in a right format\n",
        "\n",
        "preds = (np.concatenate(all_probs) >= 0.5).astype(int)   # use threshold 0.5\n",
        "preds = preds.flatten() # Flatten the array to ensure it's 1-dimensional\n",
        "\n",
        "# ---------- Build submission ----------\n",
        "submission = pd.DataFrame({\n",
        "    \"image\": all_names,\n",
        "    \"label\": preds\n",
        "})\n",
        "\n",
        "# Make sure submission order matches the test.csv\n",
        "submission = test_df[[\"image\"]].merge(submission, on=\"image\", how=\"left\")\n",
        "submission[\"label\"] = submission[\"label\"].fillna(0).astype(int)\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Saved submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibJiSQfzSOAd",
        "outputId": "87f5b7c1-53e6-4547-8f54-79121a0d9a19"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv\n"
          ]
        }
      ]
    }
  ]
}